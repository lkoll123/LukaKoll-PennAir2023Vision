
I believe that i was able to finish the entirety of the challenge to the standards outlined by the github repo. I completed each respective portion of the challenge as such:

Part 1: This part of the challenge is arguably imperfect, as it solely identifies some incomplete factor in the qr code(finder pattern for qr segments containing an eye, general qr pattern for qr segment without eye), and does not identify and outline the entirety of the qr segment.
A more useful and applicable function would identify contours surrounding the entirety of the qr code segment(although this would be difficult using contour detection, as the qr code segments do not have buffer margins), and crop the image along those contours to extract the qr code. That being said, as my detection algorithm does detect a qr code (and part 1 of the software challenge solely requires applicants to detect a qr code), I would deem my submission for part 1 of the challenge to be complete. Although coding the algorithm itself did not take very long, if I were to include time spent doing background research on the opencv functions used, along with time spent tweaking the parameters of my function to optimize for the best contour detection of the qr code, part 1 of the software challenge took me approximately 5 hours to complete. 


Part 2: I fully completed part 2 of the software challenge. The sole challenge of de-skewing the 4 cropped images did not take very long. Between background research on Opencv’s perspective transform function and its implementation, I would say this portion took me approximately 30 minutes. However, the assembly of the qr segments into a coherent and readable QR code took much longer. The first thing I did, was to identify the orientation of the qr codes. I was able to identify the orientation of the segments based off of the placement of finder patterns and timing patterns in the segment(explained in more detail in code comments) Initially, I had failed to identify that the qr code segments were of incomplete dimensions, and contained overlapping patterns. Therefore, I wasted a fair amount of time attempting to orient the four segments without cropping them, such that it produced a readable qr code. After having identified that the qr codes contain overlapping patterns, I determined the optimal dimensions at which to crop each segment, and its respective dimensions((width, height) in qr_code blocks) in the final image. I then cropped and rotated the image segments to fit the correct orientation, and modified my original algorithm to combine these segments into a coherent and readable qr code. I also polarized the image into solely black(0, 0, 0) and white(255, 255, 255) points to accentuate the qr code. My final outputted qr code, was actually fairly clean and readable, clearly outputting the 4-digit code: 0106. Between the background research on qr codes, image flattening, image cropping, and trial and error of my qr segment-combining algorithm, I would say that part 2 in its entirety took me around 6 hours. 

Part 3: I fully completed part 3 of the software challenge. This portion was incredibly easy and quick, as I simply completed it using a zbar, a python package that fully decoded the qr code for you. Although, as I wasn’t sure if the software challenge was looking for originality in code, I tried to research a way in which one could code a qr-reader from scratch without overt reliance on packages, I did not find much on the subject, and realised that this probably was not feasible given the time-frame of the software challenge. Researching the qr_decoding package, installing dependencies, and executing the code took me at most 20 minutes.




My Code: 
I coded the entirety of my software challenge using python. My Zip file submission will contain three python files, one for each portion of the software challenge. All code in each file is fairly thoroughly commented, explaining each portion of my code in detail.  

Part 1: QR_detection.py simply contains a function qr_identify that takes in a list of filepaths to the four qr code segments(list can be of any size, however), and returns a list of images of those 4 qr segments, but with contours outlining the qr code in the image. This portion utilizes packages numpy and OpenCV, so make sure that you have these dependencies installed before running the code. To execute this code, simply replace the existing file paths with file paths of the 4 qr segments on your local machine.  The code also calls the function at the end, looping through the outputted list and displaying each of the four images. If you would like to save these images, use the cv2.imwrite() function.

Part 2: QRextraction.py contains a much more lengthy code. It is made up of multiple functions, and some code in between that prepares the images(rotate, cropping, etc) to prime the images for the functions. Again, the code is fairly thoroughly commented, so I will not explain everything that happens in the code. From a bird’s eye view, the code contains two functions: One(flatten_img) that flattens the qr segments and crops them such that they do not contain overlapping qr patterns, and another that takes in a list of these flattened and rotated segments, along with a list of the dimensions(in qr code blocks) of each segment, and consolidates them into a coherent and readable qr code. The code will also display and save all four segments of the qr code, and the final qr code. This portion utilizes packages numpy, OpenCV, Pillow, os, and math, so make sure that you have the correct dependencies installed. In order to execute this code, simply replace the file paths to the original qr segments at the very top, and then towards the middle when I change directory(os.chdir) to a filepath in which I would like to save the modified qr segments. Then, you must also alter the paths to the modified qr segments towards the middle of the code. Make sure that the file paths appear in the correct order in the last, as outlined by the comments. As per the outlined corner points and image dimensions for each qr segment, this information was determined manually, and does not need altering. 

Part 3: QR_reader is a very short and concise code. In orer to execute the code, simply substitute your file path for the completed qr code image into the cv.imread function, and this code will decode the qr code, returning: 0106. 





My Zip submission file will also contain the outputted images at each step of the software challenge: contour detection, flattened images, and final qr image. Thank you so much for taking the time to review my application. Please let me know if you have any questions!
